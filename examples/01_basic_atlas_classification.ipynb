{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Atlas-Based Classification\n",
    "\n",
    "This notebook demonstrates the standard TESLearn workflow for binary classification using atlas-based features.\n",
    "\n",
    "## Approach Overview\n",
    "\n",
    "**Feature Extraction**: Atlas-based ROIs (Regions of Interest)  \n",
    "**Feature Selection**: T-test (univariate statistical test)  \n",
    "**Model**: Logistic Regression with L2 regularization  \n",
    "**Validation**: Nested Cross-Validation\n",
    "\n",
    "## Why This Works\n",
    "\n",
    "Atlas-based features aggregate electric field intensities within anatomically defined brain regions. This:\n",
    "- Reduces dimensionality (hundreds of ROIs vs millions of voxels)\n",
    "- Provides anatomically interpretable features\n",
    "- Is robust to small sample sizes common in TES studies\n",
    "\n",
    "T-test feature selection identifies ROIs that show statistically significant differences between responders and non-responders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import teslearn as tl\n",
    "from teslearn.data import load_dataset_from_csv, NiftiLoader\n",
    "from teslearn.features import AtlasFeatureExtractor\n",
    "from teslearn.models import LogisticRegressionModel\n",
    "from teslearn.selection import TTestSelector\n",
    "from teslearn.plotting import plot_roc_curve, plot_confusion_matrix\n",
    "\n",
    "print(f\"TESLearn version: {tl.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "**Best Practice**: Always validate your CSV format before loading. Required columns:\n",
    "- `subject_id`: Unique identifier\n",
    "- `simulation_name`: Stimulation configuration\n",
    "- `response`: Binary target (0/1)\n",
    "\n",
    "The `NiftiLoader` handles BIDS-style organization automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset metadata\n",
    "dataset = load_dataset_from_csv(\n",
    "    csv_path='data/subjects.csv',\n",
    "    efield_base_dir='data/derivatives/efields/',\n",
    "    target_col='response',\n",
    "    task='classification'\n",
    ")\n",
    "\n",
    "print(f\"Dataset: {dataset.n_subjects} subjects\")\n",
    "print(f\"Responders: {sum(dataset.get_targets())}\")\n",
    "print(f\"Non-responders: {len(dataset.get_targets()) - sum(dataset.get_targets())}\")\n",
    "\n",
    "# Load actual NIfTI images\n",
    "loader = NiftiLoader()\n",
    "images, indices = loader.load_dataset_images(dataset)\n",
    "y = dataset.get_targets()\n",
    "\n",
    "print(f\"\\nLoaded {len(images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction\n",
    "\n",
    "**Atlas Selection**: The Glasser HCP atlas provides 360 cortical parcels. For subcortical structures, consider Harvard-Oxford.\n",
    "\n",
    "**Statistics**: Multiple statistics capture different aspects of the E-field distribution:\n",
    "- `mean`: Average intensity (most stable)\n",
    "- `max`: Peak intensity (catches focal hotspots)\n",
    "- `top10mean`: Mean of top 10% (robust to outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure atlas-based feature extraction\n",
    "extractor = AtlasFeatureExtractor(\n",
    "    atlas_path='data/atlas/HCP-MMP1.nii.gz',\n",
    "    statistics=['mean', 'max', 'top10mean'],\n",
    "    top_percentile=90.0\n",
    ")\n",
    "\n",
    "# Extract features (this may take a moment)\n",
    "X = extractor.fit_transform(images)\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Features per ROI: {len(extractor.statistics)}\")\n",
    "print(f\"Total features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Configuration\n",
    "\n",
    "**Logistic Regression** is the default choice because:\n",
    "- Interpretable coefficients (feature importance)\n",
    "- Well-calibrated probabilities\n",
    "- Fast training and prediction\n",
    "- Works well with L2 regularization\n",
    "\n",
    "**Regularization**: `C=1.0` is a good starting point. Lower values = stronger regularization (useful for small samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure feature selection\n",
    "selector = TTestSelector(\n",
    "    p_threshold=0.001,  # Conservative threshold\n",
    "    correction=None     # Can use 'bonferroni' or 'fdr' for multiple comparisons\n",
    ")\n",
    "\n",
    "# Configure logistic regression\n",
    "model = LogisticRegressionModel(\n",
    "    C=1.0,              # Inverse regularization strength\n",
    "    penalty='l2',       # Ridge regularization\n",
    "    solver='lbfgs',     # Efficient for small-medium datasets\n",
    "    class_weight='balanced',  # Handle class imbalance\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training with Nested Cross-Validation\n",
    "\n",
    "**Why Nested CV?**\n",
    "- Outer loop: Unbiased performance estimation\n",
    "- Inner loop: Feature selection and model fitting\n",
    "- Prevents data leakage from feature selection\n",
    "\n",
    "**Best Practice**: Use stratified CV to maintain class proportions in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with nested cross-validation\n",
    "result = tl.train_model(\n",
    "    images=images,\n",
    "    y=y,\n",
    "    feature_extractor=extractor,\n",
    "    model=model,\n",
    "    feature_selector=selector,\n",
    "    outer_folds=5,      # 5-fold outer CV\n",
    "    inner_folds=3,      # 3-fold inner CV for feature selection\n",
    "    use_scaling=True    # Standardize features\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(result.get_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Interpretation\n",
    "\n",
    "Understanding which brain regions drive predictions is crucial for TES studies. We use the `explain_model` function to:\n",
    "- Extract feature importance from model coefficients\n",
    "- Map back to atlas regions\n",
    "- Generate weight maps for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teslearn.explain import explain_model\n",
    "\n",
    "# Generate model explanation\n",
    "explanation = explain_model(\n",
    "    pipeline=result.pipeline,\n",
    "    atlas_path='data/atlas/HCP-MMP1.nii.gz',\n",
    "    create_weight_maps=True,\n",
    "    output_dir='./output/atlas_explanation'\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 predictive regions:\")\n",
    "for i, (region, importance) in enumerate(explanation.top_positive[:10], 1):\n",
    "    print(f\"{i:2d}. {region}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization\n",
    "\n",
    "Plot evaluation metrics to assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot ROC curve\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# ROC Curve (using cross-validated scores)\n",
    "if hasattr(result, 'all_y_true') and hasattr(result, 'all_y_score'):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, _ = roc_curve(result.all_y_true, result.all_y_score)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    axes[0].plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    axes[0].plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    axes[0].set_xlabel('False Positive Rate')\n",
    "    axes[0].set_ylabel('True Positive Rate')\n",
    "    axes[0].set_title('ROC Curve')\n",
    "    axes[0].legend()\n",
    "\n",
    "# Feature importance\n",
    "top_features = explanation.top_positive[:15]\n",
    "axes[1].barh(range(len(top_features)), [imp for _, imp in top_features])\n",
    "axes[1].set_yticks(range(len(top_features)))\n",
    "axes[1].set_yticklabels([name for name, _ in top_features], fontsize=8)\n",
    "axes[1].set_xlabel('Feature Importance')\n",
    "axes[1].set_title('Top Predictive Regions')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Atlas features** provide anatomically interpretable, low-dimensional representations\n",
    "2. **T-test selection** reduces features while maintaining statistical rigor\n",
    "3. **Nested CV** prevents overfitting and gives unbiased performance estimates\n",
    "4. **Model interpretation** reveals which brain regions drive predictions\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try different atlases (AAL, Harvard-Oxford)\n",
    "- Experiment with voxel-based features for finer spatial resolution\n",
    "- Use permutation tests to validate significance of performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
